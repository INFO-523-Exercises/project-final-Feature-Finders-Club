

```{r}
#| label: load-pkgs
#| message: false

suppressWarnings(library(tidyverse))
library(knitr)
library(lubridate)
library(reticulate)
```


## Dataset Setup
```{python}
'''!pip install yfinance
!pip install vaderSentiment
!pip install pandas 
!pip install matplotlib
!pip install nltk
'''
```
```{python}
from dateutil import parser
import requests
import pandas as pd
import matplotlib.pyplot as plt
import yfinance
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from datetime import datetime, timedelta
```
```{python}
apple=yfinance.Ticker("AAPL")
data=apple.history(period='1mo')
```
```{python}
api_key='9dcab5d0d86940459623ec7dea5c8d36'
stock_symbol ="AAPL"
query_params = {
    'q': f'{stock_symbol}',
    'apiKey': api_key,
    'language': 'en',  # English language
    'country': 'us',   # USA sources
}
news_url = "https://newsapi.org/v2/everything"
response = requests.get(news_url, params=query_params)

end_date = datetime.now()
start_date = end_date - timedelta(days=31)

from_date = start_date.strftime("%Y-%m-%d")
to_date = end_date.strftime("%Y-%m-%d")

news_url = f"https://newsapi.org/v2/everything?q={stock_symbol}&apiKey={api_key}&from={from_date}&to={to_date}&language=en"

response = requests.get(news_url)

if response.status_code == 200:
    news_data = response.json()
    articles = news_data['articles']
    headlines = [(article['title'], article['publishedAt']) for article in articles]
else:
    print("Failed to retrieve news data.")
```
```{python}
apple_related_headlines=[]
for headline, _ in headlines:
    try:
        date = parser.parse(_)
        if 'Apple' in headline:
            apple_related_headlines.append((headline, date))
    except ValueError:
        pass
apple_related_headlines.sort(key=lambda x: x[1])
for data in apple_related_headlines:
    print(f'Headline: {data[0]}\nDate: {data[1]}\n')
df_apple_related_headlines = pd.DataFrame(apple_related_headlines, columns= ['Headlines', 'date'])
df_unique_apple_related_headlines = df_apple_related_headlines.drop_duplicates(subset=['Headlines'])
```
```{python}
analyzer = SentimentIntensityAnalyzer()
sentiments = []
neg_scores = []
neu_scores = []
pos_scores = []
compound_scores = []
for sentence in df_unique_apple_related_headlines['Headlines']:
    vs = analyzer.polarity_scores(sentence)
    sentiments.append(sentence)
    neg_scores.append(vs['neg'])
    neu_scores.append(vs['neu'])
    pos_scores.append(vs['pos'])
    compound_scores.append(vs['compound'])
```
```{python}
sentiment_df = pd.DataFrame({
    'Headlines': sentiments,
    'Negative Score': neg_scores,
    'Neutral Score': neu_scores,
    'Positive Score': pos_scores,
    'Compound Score': compound_scores
})
```
```{python}
merged_df= pd.merge(df_unique_apple_related_headlines, sentiment_df, how="inner", on=["Headlines"])
```

## Plots
```{r}

```